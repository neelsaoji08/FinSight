{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-18T19:44:39.440897Z","iopub.status.busy":"2024-04-18T19:44:39.440626Z","iopub.status.idle":"2024-04-18T19:44:53.856396Z","shell.execute_reply":"2024-04-18T19:44:53.855311Z","shell.execute_reply.started":"2024-04-18T19:44:39.440873Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\n","Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n","Collecting peft\n","  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.28.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Installing collected packages: responses, peft, evaluate\n","Successfully installed evaluate-0.4.1 peft-0.10.0 responses-0.18.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install transformers evaluate peft"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T19:44:53.858410Z","iopub.status.busy":"2024-04-18T19:44:53.858098Z","iopub.status.idle":"2024-04-18T19:45:11.569378Z","shell.execute_reply":"2024-04-18T19:45:11.568694Z","shell.execute_reply.started":"2024-04-18T19:44:53.858380Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-18 19:45:02.469679: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-18 19:45:02.469773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-18 19:45:02.577868: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm \n","from transformers import AutoTokenizer,DataCollatorWithPadding,AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from sklearn.model_selection import train_test_split\n","import evaluate\n","import torch\n","from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n","from sklearn.metrics import classification_report  \n","\n","\n","id2label = {0: \"positive\", 1: \"neutral\", 2: \"negative\"}\n","label2id = {\"positive\": 0, \"neutral\": 1, \"negative\": 2}"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T19:45:11.572029Z","iopub.status.busy":"2024-04-18T19:45:11.571299Z","iopub.status.idle":"2024-04-18T19:45:11.579446Z","shell.execute_reply":"2024-04-18T19:45:11.578474Z","shell.execute_reply.started":"2024-04-18T19:45:11.571997Z"},"trusted":true},"outputs":[],"source":["def model_prediction(model, tokenizer, text_train, text_test, labels_train, labels_test, labels):\n","    train_preds = []\n","    device = next(model.parameters()).device  # Get the device of the model\n","    for text in tqdm(text_train):\n","        inputs = tokenizer(text, return_tensors=\"pt\").to(device)  # Move tensors to model's device\n","        logits = model(**inputs)\n","        predicted_class_id = logits.logits.argmax().item()\n","        train_preds.append(id2label[predicted_class_id])\n","        \n","    test_preds = []\n","    for text in tqdm(text_test):\n","        inputs = tokenizer(text, return_tensors=\"pt\").to(device)  # Move tensors to model's device\n","        logits = model(**inputs)\n","        predicted_class_id = logits.logits.argmax().item()\n","        test_preds.append(id2label[predicted_class_id])\n","\n","#     train_report = classification_report(labels_train, train_preds, target_names=labels, digits=3)\n","#     test_report = classification_report(labels_test, test_preds, target_names=labels, digits=3)\n","\n","#     print(\"Train Classification Report: \")\n","#     print(train_report)\n","    \n","#     print(\"\\nTest Classification Report: \")\n","#     print(test_report)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T19:45:11.581036Z","iopub.status.busy":"2024-04-18T19:45:11.580706Z","iopub.status.idle":"2024-04-18T19:45:11.724157Z","shell.execute_reply":"2024-04-18T19:45:11.723201Z","shell.execute_reply.started":"2024-04-18T19:45:11.580996Z"},"trusted":true},"outputs":[],"source":["class BertDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels, label2id):\n","        self.encodings = encodings\n","        self.labels = [label2id[value] for value in labels]\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]).to('cuda:0') for key, val in self.encodings.items()}\n","        # Move labels tensor to 'cuda:0'\n","        item['labels'] = torch.tensor(self.labels[idx]).to('cuda:0')\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T19:45:11.726535Z","iopub.status.busy":"2024-04-18T19:45:11.726203Z","iopub.status.idle":"2024-04-18T19:45:11.736242Z","shell.execute_reply":"2024-04-18T19:45:11.735389Z","shell.execute_reply.started":"2024-04-18T19:45:11.726497Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    accuracy= evaluate.load('accuracy')\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return accuracy.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T19:46:08.148377Z","iopub.status.busy":"2024-04-18T19:46:08.147456Z","iopub.status.idle":"2024-04-18T19:46:08.160171Z","shell.execute_reply":"2024-04-18T19:46:08.159092Z","shell.execute_reply.started":"2024-04-18T19:46:08.148318Z"},"trusted":true},"outputs":[],"source":["def model_train(model,tokenizer,path,name):\n","    data=pd.read_csv(path,encoding='latin-1', header=None)\n","    data.columns=['labels','text']\n","\n","    \n","    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","    texts = data[\"text\"].to_list()\n","    labels = data[\"labels\"].to_list()\n","    text_train, text_test, labels_train, labels_test = train_test_split(  \n","        texts, labels, test_size=0.20, random_state=42,   \n","    )  \n","    tokenized_text_train = tokenizer(text_train,truncation=True)\n","    tokenized_text_test = tokenizer(text_test,truncation=True)\n","\n","    print(\"train size:\", len(labels_train))\n","    print(\"test size:\", len(labels_test))\n","\n","\n","\n","    train_dataset = BertDataset(tokenized_text_train, labels_train, label2id)\n","    test_dataset = BertDataset(tokenized_text_test, labels_test, label2id)\n","    \n","    if name=='distilbert':\n","        peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n","                        r=8,\n","                        lora_alpha=32,\n","                        lora_dropout=0.01,\n","                        target_modules = ['q_lin']\n","                            )\n","    else:\n","         peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n","                        r=8,\n","                        lora_alpha=32,\n","                        lora_dropout=0.01\n","                            )\n","        \n","\n","    model = get_peft_model(model, peft_config)\n","    model.print_trainable_parameters()\n","    \n","    \n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    training_args = TrainingArguments(\n","    output_dir=f\"new_model_{name}\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=15,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    push_to_hub=False,\n","    report_to=\"none\"\n","    )\n","\n","    trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    )\n","    trainer.train()\n","    model = trainer.model\n","    \n","    \n","    return model,text_train,text_test,labels_train,labels_test,labels"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T19:45:39.179706Z","iopub.status.busy":"2024-04-18T19:45:39.179324Z","iopub.status.idle":"2024-04-18T19:45:44.479325Z","shell.execute_reply":"2024-04-18T19:45:44.478284Z","shell.execute_reply.started":"2024-04-18T19:45:39.179678Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3a289f2a7ec4914ac08e43975d2e4c4","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/369 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2775c2ce48294bd3ae575ab4fc66d3a4","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91f5bc0407684fd3bf8c0129639d2a22","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/464k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ad7891563874b649d56ab4bb608496f","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b65f69df1b4b40a6bb12c555869d05f2","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/789 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a7422f8c56848159ccf43f6d31dd627","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}],"source":["path='/kaggle/input/sentiment-analysis-for-financial-news/all-data.csv'\n","tokenizer_FinancialBERT = AutoTokenizer.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\")\n","model_FinancialBERT = AutoModelForSequenceClassification.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\", num_labels=3)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T19:46:33.346799Z","iopub.status.busy":"2024-04-18T19:46:33.346447Z","iopub.status.idle":"2024-04-18T19:55:07.155619Z","shell.execute_reply":"2024-04-18T19:55:07.154855Z","shell.execute_reply.started":"2024-04-18T19:46:33.346773Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train size: 3876\n","test size: 970\n","trainable params: 297,219 || all params: 110,051,334 || trainable%: 0.27007305517986724\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1830' max='1830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1830/1830 08:29, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.769620</td>\n","      <td>0.584536</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.641242</td>\n","      <td>0.711340</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.534681</td>\n","      <td>0.768041</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.480188</td>\n","      <td>0.795876</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.377700</td>\n","      <td>0.430278</td>\n","      <td>0.824742</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.377700</td>\n","      <td>0.389697</td>\n","      <td>0.836082</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.377700</td>\n","      <td>0.348974</td>\n","      <td>0.858763</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.377700</td>\n","      <td>0.314565</td>\n","      <td>0.888660</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.390900</td>\n","      <td>0.280993</td>\n","      <td>0.910309</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.390900</td>\n","      <td>0.251621</td>\n","      <td>0.920619</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.390900</td>\n","      <td>0.235103</td>\n","      <td>0.925773</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.390900</td>\n","      <td>0.224527</td>\n","      <td>0.930928</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.255300</td>\n","      <td>0.214810</td>\n","      <td>0.932990</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.255300</td>\n","      <td>0.210336</td>\n","      <td>0.935052</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.255300</td>\n","      <td>0.209003</td>\n","      <td>0.936082</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad0b10a5211c4525b83991bc6087a6d0","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]}],"source":["model_FinancialBERT.to(\"cuda:0\")\n","model_FinancialBERT,text_train,text_test,labels_train,labels_test,labels=model_train(model_FinancialBERT,tokenizer_FinancialBERT,path,\"FinancialBERT\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-17T19:45:01.543592Z","iopub.status.idle":"2024-04-17T19:45:01.543931Z","shell.execute_reply":"2024-04-17T19:45:01.543770Z","shell.execute_reply.started":"2024-04-17T19:45:01.543756Z"},"trusted":true},"outputs":[],"source":["model_prediction(model_finbert,tokenizer_finbert,text_train,text_test,labels_train,labels_test,labels)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T19:55:07.157728Z","iopub.status.busy":"2024-04-18T19:55:07.157150Z","iopub.status.idle":"2024-04-18T19:55:11.577534Z","shell.execute_reply":"2024-04-18T19:55:11.576507Z","shell.execute_reply.started":"2024-04-18T19:55:07.157699Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03601d3c969b40de9b90a35d7a776a7d","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84c3709c703f4e1ca4b4087c3e664624","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51cd6698190e4dc1bb3e502164336003","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5c57b7196c04c589a3f6e0ae7b64c5a","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db4d97e0cbcd4fe1905ac5823ac81385","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer_finbert = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n","model_finbert = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\", num_labels=3)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T19:55:11.579059Z","iopub.status.busy":"2024-04-18T19:55:11.578770Z","iopub.status.idle":"2024-04-18T20:03:31.530053Z","shell.execute_reply":"2024-04-18T20:03:31.529101Z","shell.execute_reply.started":"2024-04-18T19:55:11.579034Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train size: 3876\n","test size: 970\n","trainable params: 297,219 || all params: 109,781,766 || trainable%: 0.27073621679578375\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1830' max='1830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1830/1830 08:18, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.951978</td>\n","      <td>0.601031</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.596295</td>\n","      <td>0.786598</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.520068</td>\n","      <td>0.804124</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.456558</td>\n","      <td>0.806186</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.942400</td>\n","      <td>0.374503</td>\n","      <td>0.878351</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.942400</td>\n","      <td>0.308682</td>\n","      <td>0.896907</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.942400</td>\n","      <td>0.277229</td>\n","      <td>0.903093</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.942400</td>\n","      <td>0.267559</td>\n","      <td>0.906186</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.348900</td>\n","      <td>0.261233</td>\n","      <td>0.906186</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.348900</td>\n","      <td>0.258094</td>\n","      <td>0.909278</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.348900</td>\n","      <td>0.255484</td>\n","      <td>0.909278</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.348900</td>\n","      <td>0.254663</td>\n","      <td>0.910309</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.275800</td>\n","      <td>0.253877</td>\n","      <td>0.910309</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.275800</td>\n","      <td>0.253674</td>\n","      <td>0.910309</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.275800</td>\n","      <td>0.253399</td>\n","      <td>0.910309</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]}],"source":["model_finbert.to(\"cuda:0\")\n","model_finbert,text_train,text_test,labels_train,labels_test,labels=model_train(model_finbert,tokenizer_finbert,path,\"finbert\")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T20:15:37.129925Z","iopub.status.busy":"2024-04-18T20:15:37.129188Z","iopub.status.idle":"2024-04-18T20:15:37.677672Z","shell.execute_reply":"2024-04-18T20:15:37.676846Z","shell.execute_reply.started":"2024-04-18T20:15:37.129891Z"},"trusted":true},"outputs":[],"source":["tokenizer_distilbert = AutoTokenizer.from_pretrained(\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\")\n","model_distilbert = AutoModelForSequenceClassification.from_pretrained(\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", num_labels=3)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T20:15:40.227954Z","iopub.status.busy":"2024-04-18T20:15:40.227581Z","iopub.status.idle":"2024-04-18T20:21:44.090320Z","shell.execute_reply":"2024-04-18T20:21:44.089564Z","shell.execute_reply.started":"2024-04-18T20:15:40.227927Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train size: 3876\n","test size: 970\n","trainable params: 666,627 || all params: 135,993,606 || trainable%: 0.4901899579014031\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1830' max='1830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1830/1830 06:02, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.817471</td>\n","      <td>0.591753</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.759601</td>\n","      <td>0.620619</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.713132</td>\n","      <td>0.669072</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.677984</td>\n","      <td>0.695876</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.773800</td>\n","      <td>0.654519</td>\n","      <td>0.707216</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.773800</td>\n","      <td>0.634968</td>\n","      <td>0.720619</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.773800</td>\n","      <td>0.622085</td>\n","      <td>0.727835</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.773800</td>\n","      <td>0.611244</td>\n","      <td>0.736082</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.611400</td>\n","      <td>0.602229</td>\n","      <td>0.739175</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.611400</td>\n","      <td>0.595562</td>\n","      <td>0.742268</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.611400</td>\n","      <td>0.591071</td>\n","      <td>0.744330</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.611400</td>\n","      <td>0.586495</td>\n","      <td>0.747423</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.570200</td>\n","      <td>0.583663</td>\n","      <td>0.749485</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.570200</td>\n","      <td>0.582243</td>\n","      <td>0.749485</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.570200</td>\n","      <td>0.581911</td>\n","      <td>0.750515</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]}],"source":["model_distilbert.to(\"cuda:0\")\n","model_distilbert,text_train,text_test,labels_train,labels_test,labels=model_train(model_distilbert,tokenizer_distilbert,path,\"distilbert\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T20:21:44.091968Z","iopub.status.busy":"2024-04-18T20:21:44.091690Z","iopub.status.idle":"2024-04-18T20:21:44.565408Z","shell.execute_reply":"2024-04-18T20:21:44.564605Z","shell.execute_reply.started":"2024-04-18T20:21:44.091943Z"},"trusted":true},"outputs":[],"source":["model_FinancialBERT.save_pretrained('model_FinancialBERT')\n","model_FinancialBERT.save_pretrained('model_distilbert')\n","model_finbert.save_pretrained('model_finbert')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lora_config = LoraConfig.from_pretrained('/content/drive/MyDrive/model_FinancialBERT')\n","model = get_peft_model(model_FinancialBERT, lora_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer,AutoModelForSequenceClassification\n","from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokenizer_FinancialBERT = AutoTokenizer.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\")\n","model_FinancialBERT = AutoModelForSequenceClassification.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\", num_labels=3)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":622510,"sourceId":1192499,"sourceType":"datasetVersion"},{"datasetId":2235428,"sourceId":3740661,"sourceType":"datasetVersion"}],"dockerImageVersionId":30684,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
